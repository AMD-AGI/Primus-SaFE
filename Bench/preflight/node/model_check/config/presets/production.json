{
    "debug": {
        "enabled": false,
        "log_level": "INFO"
    },
    "model": {
        "model_type": "llama",
        "model_path": "meta-llama/Llama-3.1-8B-Instruct",
        "num_layers": 32,
        "init_std": 0.02,
        "use_flash_attention": true
    },
    "training": {
        "batch_size": 4,
        "grad_accum_nums": 8,
        "context_length": 8192,
        "max_steps": 10000,
        "warmup_steps": 500,
        "learning_rate": 1e-4,
        "weight_decay": 0.1,
        "adam_beta1": 0.9,
        "adam_beta2": 0.95,
        "adam_epsilon": 1e-8,
        "max_grad_norm": 1.0,
        "use_amp": true,
        "amp_dtype": "bfloat16",
        "save_interval": 500,
        "eval_interval": 100
    },
    "data": {
        "dataset_name": "wikitext",
        "num_workers": 4,
        "pin_memory": true,
        "prefetch_factor": 2
    },
    "system": {
        "device": "cuda",
        "seed": 42,
        "gradient_checkpointing": false,
        "empty_cache_interval": 50
    },
    "experiment_name": "llama_production"
}
