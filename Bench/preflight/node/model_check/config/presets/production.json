{
  "debug": {
    "enabled": false,
    "log_level": "INFO"
  },
  "model": {
    "model_type": "qwen3",
    "model_path": "Qwen/Qwen3-8B",
    "num_layers": 4,
    "init_std": 0.02,
    "use_flash_attention": true
  },
  "training": {
    "batch_size": 4,
    "grad_accum_nums": 8,
    "context_length": 8192,
    "max_steps": 12,
    "warmup_steps": 6,
    "learning_rate": 0.0005,
    "weight_decay": 0.1,
    "adam_beta1": 0.9,
    "adam_beta2": 0.95,
    "adam_epsilon": 1e-08,
    "max_grad_norm": 1.0,
    "use_amp": true,
    "amp_dtype": "bfloat16",
    "save_interval": 50,
    "eval_interval": 50,
    "patience": 1000,
    "min_delta": 0.0001
  },
  "data": {
    "dataset_name": "wikitext",
    "num_workers": 4,
    "pin_memory": true,
    "prefetch_factor": 2
  },
  "system": {
    "device": "cuda",
    "seed": 42,
    "gradient_checkpointing": false,
    "empty_cache_interval": 10
  },
  "experiment_name": "llama_production"
}