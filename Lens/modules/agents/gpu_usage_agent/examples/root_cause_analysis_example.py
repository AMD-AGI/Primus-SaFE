#!/usr/bin/env python3
"""
GPU ä½¿ç”¨ç‡ä¸‹é™æ ¹å› åˆ†æç¤ºä¾‹

æœ¬ç¤ºä¾‹å±•ç¤ºå¦‚ä½•ä½¿ç”¨æ–°å¢çš„ get_available_dimension_values æ–¹æ³•
æ¥åˆ†æé›†ç¾¤ GPU ä½¿ç”¨ç‡ä¸‹é™çš„æ ¹æœ¬åŸå› ã€‚
"""

import json
import sys
from typing import Dict, List, Tuple
from datetime import datetime, timedelta

# å‡è®¾å·²ç»å®‰è£…äº†å¿…è¦çš„ä¾èµ–
sys.path.insert(0, '..')
from tools import GPUAnalysisTools
from utils import safe_json_parse


class UsageRootCauseAnalyzer:
    """GPU ä½¿ç”¨ç‡ä¸‹é™æ ¹å› åˆ†æå™¨"""
    
    def __init__(self, api_base_url: str, cluster_name: str = None):
        """
        åˆå§‹åŒ–åˆ†æå™¨
        
        Args:
            api_base_url: API åŸºç¡€ URL
            cluster_name: é›†ç¾¤åç§°ï¼ˆå¯é€‰ï¼‰
        """
        self.tools = GPUAnalysisTools(api_base_url, cluster_name)
        self.cluster_name = cluster_name
    
    def analyze_cluster_trend(self, time_range_days: int = 7) -> Dict:
        """
        åˆ†æé›†ç¾¤çº§åˆ«çš„ä½¿ç”¨ç‡è¶‹åŠ¿
        
        Returns:
            åŒ…å«è¶‹åŠ¿ä¿¡æ¯çš„å­—å…¸
        """
        print(f"ğŸ“Š æ­¥éª¤ 1: åˆ†æé›†ç¾¤æ•´ä½“ä½¿ç”¨ç‡è¶‹åŠ¿ï¼ˆæœ€è¿‘ {time_range_days} å¤©ï¼‰...")
        
        result = self.tools.query_gpu_usage_trend(
            dimension="cluster",
            granularity="day",
            time_range_days=time_range_days,
            metric_type="utilization"
        )
        
        data = safe_json_parse(result)
        if not data:
            print("   âš ï¸ æ— æ³•è§£ææ•°æ®")
            return {}
        stats = data.get("statistics", {})
        
        print(f"   å¹³å‡ä½¿ç”¨ç‡: {stats.get('average', 0):.2f}%")
        print(f"   æœ€é«˜ä½¿ç”¨ç‡: {stats.get('max', 0):.2f}%")
        print(f"   æœ€ä½ä½¿ç”¨ç‡: {stats.get('min', 0):.2f}%")
        print(f"   è¶‹åŠ¿: {stats.get('trend', 'unknown')}")
        
        return data
    
    def analyze_by_namespace(self, time_range_days: int = 7) -> List[Tuple[str, float]]:
        """
        æŒ‰ namespace åˆ†æä½¿ç”¨ç‡
        
        Returns:
            (namespace, å¹³å‡ä½¿ç”¨ç‡) çš„åˆ—è¡¨ï¼ŒæŒ‰ä½¿ç”¨ç‡å‡åºæ’åˆ—
        """
        print(f"\nğŸ“¦ æ­¥éª¤ 2: æŒ‰ Namespace åˆ†æ...")
        
        # è·å–æ‰€æœ‰ namespaces
        namespaces_result = self.tools.get_available_namespaces(time_range_days)
        namespaces_data = safe_json_parse(namespaces_result)
        if not namespaces_data:
            print("   âš ï¸ æ— æ³•è§£æ namespaces æ•°æ®")
            return []
        namespaces = namespaces_data.get('namespaces', [])
        
        print(f"   å‘ç° {len(namespaces)} ä¸ª namespaces")
        
        # æŸ¥è¯¢æ¯ä¸ª namespace çš„ä½¿ç”¨ç‡
        namespace_stats = []
        for ns in namespaces:
            result = self.tools.query_gpu_usage_trend(
                dimension="namespace",
                dimension_value=ns,
                granularity="day",
                time_range_days=time_range_days,
                metric_type="utilization"
            )
            
            data = safe_json_parse(result)
            if not data:
                continue
            avg_util = data.get("statistics", {}).get("average", 0)
            namespace_stats.append((ns, avg_util))
            print(f"     - {ns}: {avg_util:.2f}%")
        
        # æŒ‰ä½¿ç”¨ç‡æ’åºï¼ˆä»ä½åˆ°é«˜ï¼‰
        namespace_stats.sort(key=lambda x: x[1])
        
        return namespace_stats
    
    def analyze_by_dimension(
        self, 
        dimension_type: str, 
        time_range_days: int = 7,
        top_n: int = 5
    ) -> List[Tuple[str, str, float]]:
        """
        æŒ‰ label æˆ– annotation åˆ†æä½¿ç”¨ç‡
        
        Args:
            dimension_type: "label" æˆ– "annotation"
            time_range_days: æ—¶é—´èŒƒå›´
            top_n: è¿”å›ä½¿ç”¨ç‡æœ€ä½çš„å‰ N ä¸ª
        
        Returns:
            (key, value, å¹³å‡ä½¿ç”¨ç‡) çš„åˆ—è¡¨ï¼ŒæŒ‰ä½¿ç”¨ç‡å‡åºæ’åˆ—
        """
        print(f"\nğŸ·ï¸  æ­¥éª¤ 3: æŒ‰ {dimension_type.upper()} åˆ†æ...")
        
        # è·å–æ‰€æœ‰ dimension keys
        keys_result = self.tools.get_available_dimension_keys(
            dimension_type=dimension_type,
            time_range_days=time_range_days
        )
        keys_data = safe_json_parse(keys_result)
        if not keys_data:
            print(f"   âš ï¸ æ— æ³•è§£æ {dimension_type} keys æ•°æ®")
            return []
        dimension_keys = keys_data.get('dimension_keys', [])
        
        print(f"   å‘ç° {len(dimension_keys)} ä¸ª {dimension_type} keys")
        
        # å¯¹æ¯ä¸ª keyï¼Œè·å–æ‰€æœ‰ values å¹¶æŸ¥è¯¢ä½¿ç”¨ç‡
        dimension_stats = []
        for key in dimension_keys:
            print(f"\n   åˆ†æ {dimension_type} key: {key}")
            
            # ã€æ–°åŠŸèƒ½ã€‘è·å–è¯¥ key çš„æ‰€æœ‰ values
            values_result = self.tools.get_available_dimension_values(
                dimension_type=dimension_type,
                dimension_key=key,
                time_range_days=time_range_days
            )
            values_data = safe_json_parse(values_result)
            if not values_data:
                print(f"     âš ï¸ æ— æ³•è§£æ {key} çš„ values æ•°æ®")
                continue
            values = values_data.get('dimension_values', [])
            
            print(f"     å‘ç° {len(values)} ä¸ªä¸åŒçš„ values")
            
            # æŸ¥è¯¢æ¯ä¸ª value çš„ä½¿ç”¨ç‡
            for value in values[:10]:  # é™åˆ¶æ¯ä¸ª key æœ€å¤šæŸ¥ 10 ä¸ª values
                result = self.tools.query_gpu_usage_trend(
                    dimension="label" if dimension_type == "label" else "annotation",
                    dimension_value=f"{key}:{value}",
                    granularity="day",
                    time_range_days=time_range_days,
                    metric_type="utilization"
                )
                
                data = safe_json_parse(result)
                if data and 'error' not in data:
                    avg_util = data.get("statistics", {}).get("average", 0)
                    dimension_stats.append((key, value, avg_util))
                    print(f"       - {value}: {avg_util:.2f}%")
        
        # æŒ‰ä½¿ç”¨ç‡æ’åºï¼ˆä»ä½åˆ°é«˜ï¼‰
        dimension_stats.sort(key=lambda x: x[2])
        
        # è¿”å›ä½¿ç”¨ç‡æœ€ä½çš„å‰ N ä¸ª
        return dimension_stats[:top_n]
    
    def generate_report(
        self,
        cluster_data: Dict,
        namespace_stats: List[Tuple[str, float]],
        label_stats: List[Tuple[str, str, float]],
        annotation_stats: List[Tuple[str, str, float]]
    ):
        """
        ç”Ÿæˆåˆ†ææŠ¥å‘Š
        """
        print("\n" + "="*80)
        print("ğŸ“ˆ GPU ä½¿ç”¨ç‡ä¸‹é™æ ¹å› åˆ†ææŠ¥å‘Š")
        print("="*80)
        
        # é›†ç¾¤æ•´ä½“æƒ…å†µ
        stats = cluster_data.get("statistics", {})
        print(f"\nã€é›†ç¾¤æ•´ä½“æƒ…å†µã€‘")
        print(f"  å¹³å‡ä½¿ç”¨ç‡: {stats.get('average', 0):.2f}%")
        print(f"  è¶‹åŠ¿: {stats.get('trend', 'unknown')}")
        
        if stats.get('trend') == 'decreasing':
            print(f"  âš ï¸  ä½¿ç”¨ç‡å‘ˆä¸‹é™è¶‹åŠ¿ï¼")
        
        # Namespace åˆ†æ
        print(f"\nã€Namespace ä½¿ç”¨ç‡æœ€ä½çš„å‰ 3 åã€‘")
        for i, (ns, util) in enumerate(namespace_stats[:3], 1):
            print(f"  {i}. {ns}: {util:.2f}%")
        
        # Label åˆ†æ
        print(f"\nã€Label ä½¿ç”¨ç‡æœ€ä½çš„å‰ 3 åã€‘")
        if label_stats:
            for i, (key, value, util) in enumerate(label_stats[:3], 1):
                print(f"  {i}. {key}={value}: {util:.2f}%")
        else:
            print("  æ— æ•°æ®")
        
        # Annotation åˆ†æ
        print(f"\nã€Annotation ä½¿ç”¨ç‡æœ€ä½çš„å‰ 3 åã€‘")
        if annotation_stats:
            for i, (key, value, util) in enumerate(annotation_stats[:3], 1):
                print(f"  {i}. {key}={value}: {util:.2f}%")
        else:
            print("  æ— æ•°æ®")
        
        # æ ¹å› æ¨æ–­
        print(f"\nã€å¯èƒ½çš„æ ¹å› ã€‘")
        all_low_util = []
        all_low_util.extend([(f"namespace:{ns}", util) for ns, util in namespace_stats[:3]])
        all_low_util.extend([(f"label:{k}={v}", util) for k, v, util in label_stats[:3]])
        all_low_util.extend([(f"annotation:{k}={v}", util) for k, v, util in annotation_stats[:3]])
        
        # æŒ‰ä½¿ç”¨ç‡æ’åº
        all_low_util.sort(key=lambda x: x[1])
        
        for i, (dimension, util) in enumerate(all_low_util[:5], 1):
            print(f"  {i}. {dimension} çš„å¹³å‡ä½¿ç”¨ç‡ä»…ä¸º {util:.2f}%")
            print(f"     å»ºè®®æ£€æŸ¥è¯¥ç»´åº¦ä¸‹çš„ä»»åŠ¡æ˜¯å¦å­˜åœ¨èµ„æºæµªè´¹æˆ–é…ç½®é—®é¢˜")
        
        print("\n" + "="*80)


def main():
    """ä¸»å‡½æ•°"""
    # é…ç½®
    API_BASE_URL = "http://localhost:8080"
    CLUSTER_NAME = "default"  # å¯é€‰
    TIME_RANGE_DAYS = 7
    
    print("ğŸš€ å¼€å§‹ GPU ä½¿ç”¨ç‡ä¸‹é™æ ¹å› åˆ†æ...")
    print(f"   API: {API_BASE_URL}")
    print(f"   é›†ç¾¤: {CLUSTER_NAME or '(é»˜è®¤)'}")
    print(f"   æ—¶é—´èŒƒå›´: æœ€è¿‘ {TIME_RANGE_DAYS} å¤©")
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = UsageRootCauseAnalyzer(API_BASE_URL, CLUSTER_NAME)
    
    try:
        # æ­¥éª¤ 1: åˆ†æé›†ç¾¤è¶‹åŠ¿
        cluster_data = analyzer.analyze_cluster_trend(TIME_RANGE_DAYS)
        
        # æ­¥éª¤ 2: æŒ‰ namespace åˆ†æ
        namespace_stats = analyzer.analyze_by_namespace(TIME_RANGE_DAYS)
        
        # æ­¥éª¤ 3: æŒ‰ label åˆ†æ
        label_stats = analyzer.analyze_by_dimension("label", TIME_RANGE_DAYS, top_n=5)
        
        # æ­¥éª¤ 4: æŒ‰ annotation åˆ†æ
        annotation_stats = analyzer.analyze_by_dimension("annotation", TIME_RANGE_DAYS, top_n=5)
        
        # ç”ŸæˆæŠ¥å‘Š
        analyzer.generate_report(
            cluster_data,
            namespace_stats,
            label_stats,
            annotation_stats
        )
        
    except Exception as e:
        print(f"\nâŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    print("\nâœ… åˆ†æå®Œæˆï¼")
    return 0


if __name__ == "__main__":
    sys.exit(main())

