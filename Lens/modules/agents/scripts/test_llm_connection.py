"""æµ‹è¯•LLMè¿æ¥å’Œè¯Šæ–­é—®é¢˜

è¿™ä¸ªè„šæœ¬ç”¨äºæµ‹è¯•LLM APIè¿æ¥ï¼Œè¾“å‡ºè¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
"""

import os
import sys
import logging
import traceback

# è®¾ç½®è¯¦ç»†æ—¥å¿—
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ä¸ºOpenAIè®¾ç½®DEBUGçº§åˆ«
openai_logger = logging.getLogger("openai")
openai_logger.setLevel(logging.DEBUG)

httpx_logger = logging.getLogger("httpx")
httpx_logger.setLevel(logging.DEBUG)

def test_openai_connection():
    """æµ‹è¯•OpenAIè¿æ¥"""
    print("\n" + "="*80)
    print("æµ‹è¯• OpenAI API è¿æ¥")
    print("="*80 + "\n")
    
    try:
        from langchain_openai import ChatOpenAI
        from langchain_core.messages import SystemMessage
        
        # ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®
        api_key = os.getenv("OPENAI_API_KEY", "")
        base_url = os.getenv("OPENAI_BASE_URL", None)
        model = os.getenv("OPENAI_MODEL", "gpt-4")
        
        print(f"é…ç½®ä¿¡æ¯:")
        print(f"  API Key: {api_key[:10]}... (éšè—)" if api_key else "  API Key: æœªè®¾ç½®")
        print(f"  Base URL: {base_url if base_url else 'ä½¿ç”¨é»˜è®¤URL'}")
        print(f"  Model: {model}")
        print()
        
        if not api_key:
            print("âŒ é”™è¯¯: OPENAI_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®")
            print("è¯·è®¾ç½®ç¯å¢ƒå˜é‡:")
            print("  export OPENAI_API_KEY='your-api-key'")
            return False
        
        print("æ­£åœ¨åˆå§‹åŒ– ChatOpenAI å®¢æˆ·ç«¯...")
        llm = ChatOpenAI(
            model=model,
            api_key=api_key,
            base_url=base_url,
            temperature=0,
            max_tokens=100,
            timeout=30
        )
        
        print("âœ“ å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        print()
        
        print("æ­£åœ¨å‘é€æµ‹è¯•è¯·æ±‚...")
        messages = [SystemMessage(content="è¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ã€‚")]
        
        response = llm.invoke(messages)
        
        print("âœ“ è¯·æ±‚æˆåŠŸ!")
        print(f"\nå“åº”å†…å®¹: {response.content[:200]}...\n")
        
        return True
        
    except Exception as e:
        error_type = type(e).__name__
        error_msg = str(e)
        error_traceback = traceback.format_exc()
        
        print("\n" + "="*80)
        print("âŒ è¿æ¥å¤±è´¥")
        print("="*80)
        print(f"\né”™è¯¯ç±»å‹: {error_type}")
        print(f"é”™è¯¯æ¶ˆæ¯: {error_msg}")
        print(f"\nå®Œæ•´å †æ ˆè·Ÿè¸ª:\n{error_traceback}")
        print("="*80 + "\n")
        
        # å¸¸è§é—®é¢˜è¯Šæ–­
        print("å¯èƒ½çš„åŸå› :")
        if "APIConnectionError" in error_type or "Connection" in str(e):
            print("  1. ç½‘ç»œè¿æ¥é—®é¢˜")
            print("  2. Base URLé…ç½®é”™è¯¯")
            print("  3. é˜²ç«å¢™æˆ–ä»£ç†è®¾ç½®")
        elif "AuthenticationError" in error_type or "401" in str(e):
            print("  1. API Key é”™è¯¯æˆ–è¿‡æœŸ")
            print("  2. API Key æ ¼å¼ä¸æ­£ç¡®")
        elif "RateLimitError" in error_type or "429" in str(e):
            print("  1. APIè°ƒç”¨é¢‘ç‡è¶…é™")
            print("  2. è´¦æˆ·é¢åº¦ä¸è¶³")
        elif "APIError" in error_type or "500" in str(e):
            print("  1. OpenAIæœåŠ¡å™¨é”™è¯¯")
            print("  2. è¯·ç¨åé‡è¯•")
        
        print("\nå»ºè®®:")
        print("  1. æ£€æŸ¥ç¯å¢ƒå˜é‡è®¾ç½®")
        print("  2. ç¡®è®¤API Keyæœ‰æ•ˆæ€§")
        print("  3. æ£€æŸ¥ç½‘ç»œè¿æ¥")
        print("  4. æŸ¥çœ‹OpenAIçŠ¶æ€é¡µé¢: https://status.openai.com/")
        print()
        
        return False


def test_config_loading():
    """æµ‹è¯•é…ç½®åŠ è½½"""
    print("\n" + "="*80)
    print("æµ‹è¯•é…ç½®åŠ è½½")
    print("="*80 + "\n")
    
    try:
        # æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„
        sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))
        
        from config import load_config, get_config
        
        print("æ­£åœ¨åŠ è½½é…ç½®æ–‡ä»¶...")
        config = load_config()
        
        print("âœ“ é…ç½®åŠ è½½æˆåŠŸ")
        print()
        
        # æ˜¾ç¤ºå…³é”®é…ç½®
        print("å…³é”®é…ç½®é¡¹:")
        print(f"  LLM Provider: {get_config('llm.provider', 'N/A')}")
        print(f"  LLM Model: {get_config('llm.model', 'N/A')}")
        print(f"  LLM Base URL: {get_config('llm.base_url', 'é»˜è®¤')}")
        print(f"  Lens API URL: {get_config('lens.api_url', 'N/A')}")
        print(f"  Cache Enabled: {get_config('cache.enabled', False)}")
        print()
        
        return True
        
    except Exception as e:
        print(f"âŒ é…ç½®åŠ è½½å¤±è´¥: {str(e)}")
        print(f"\nå®Œæ•´å †æ ˆè·Ÿè¸ª:\n{traceback.format_exc()}")
        return False


def test_lens_api_connection():
    """æµ‹è¯•Lens APIè¿æ¥"""
    print("\n" + "="*80)
    print("æµ‹è¯• Lens API è¿æ¥")
    print("="*80 + "\n")
    
    try:
        import requests
        
        # ä»ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶è¯»å–
        api_url = os.getenv("LENS_API_URL", "http://localhost:30182")
        
        print(f"Lens API URL: {api_url}")
        print()
        
        print("æ­£åœ¨æµ‹è¯•è¿æ¥...")
        
        # æµ‹è¯•clustersæ¥å£
        test_url = f"{api_url}/v1/gpu-aggregation/clusters"
        response = requests.get(test_url, timeout=5)
        
        print(f"âœ“ è¿æ¥æˆåŠŸ (çŠ¶æ€ç : {response.status_code})")
        
        if response.status_code == 200:
            data = response.json()
            print(f"å“åº”æ•°æ®: {data}")
        
        print()
        return True
        
    except requests.exceptions.ConnectionError as e:
        print(f"âŒ è¿æ¥å¤±è´¥: æ— æ³•è¿æ¥åˆ° {api_url}")
        print(f"é”™è¯¯: {str(e)}")
        print("\nå»ºè®®:")
        print("  1. æ£€æŸ¥Lens APIæœåŠ¡æ˜¯å¦è¿è¡Œ")
        print("  2. ç¡®è®¤URLé…ç½®æ­£ç¡®")
        print("  3. æ£€æŸ¥é˜²ç«å¢™è®¾ç½®")
        print()
        return False
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        print(f"\nå®Œæ•´å †æ ˆè·Ÿè¸ª:\n{traceback.format_exc()}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "="*80)
    print("GPU Usage Analysis Agent - è¿æ¥è¯Šæ–­å·¥å…·")
    print("="*80)
    
    results = []
    
    # 1. æµ‹è¯•é…ç½®åŠ è½½
    results.append(("é…ç½®åŠ è½½", test_config_loading()))
    
    # 2. æµ‹è¯•LLMè¿æ¥
    results.append(("LLMè¿æ¥", test_openai_connection()))
    
    # 3. æµ‹è¯•Lens APIè¿æ¥
    results.append(("Lens APIè¿æ¥", test_lens_api_connection()))
    
    # æ˜¾ç¤ºæ€»ç»“
    print("\n" + "="*80)
    print("è¯Šæ–­æ€»ç»“")
    print("="*80 + "\n")
    
    for name, success in results:
        status = "âœ“ é€šè¿‡" if success else "âŒ å¤±è´¥"
        print(f"  {name:20} {status}")
    
    all_passed = all(success for _, success in results)
    
    if all_passed:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Agentåº”è¯¥å¯ä»¥æ­£å¸¸å·¥ä½œã€‚")
    else:
        print("\nâš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ ¹æ®ä¸Šè¿°é”™è¯¯ä¿¡æ¯è¿›è¡Œæ’æŸ¥ã€‚")
    
    print()


if __name__ == "__main__":
    main()

