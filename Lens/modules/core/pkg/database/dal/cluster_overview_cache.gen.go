// Code generated by gorm.io/gen. DO NOT EDIT.
// Code generated by gorm.io/gen. DO NOT EDIT.
// Code generated by gorm.io/gen. DO NOT EDIT.

package dal

import (
	"context"

	"gorm.io/gorm"
	"gorm.io/gorm/clause"
	"gorm.io/gorm/schema"

	"gorm.io/gen"
	"gorm.io/gen/field"

	"gorm.io/plugin/dbresolver"

	"github.com/AMD-AGI/primus-lens/core/pkg/database/model"
)

func newClusterOverviewCache(db *gorm.DB, opts ...gen.DOOption) clusterOverviewCache {
	_clusterOverviewCache := clusterOverviewCache{}

	_clusterOverviewCache.clusterOverviewCacheDo.UseDB(db, opts...)
	_clusterOverviewCache.clusterOverviewCacheDo.UseModel(&model.ClusterOverviewCache{})

	tableName := _clusterOverviewCache.clusterOverviewCacheDo.TableName()
	_clusterOverviewCache.ALL = field.NewAsterisk(tableName)
	_clusterOverviewCache.ID = field.NewInt32(tableName, "id")
	_clusterOverviewCache.ClusterName = field.NewString(tableName, "cluster_name")
	_clusterOverviewCache.TotalNodes = field.NewInt32(tableName, "total_nodes")
	_clusterOverviewCache.HealthyNodes = field.NewInt32(tableName, "healthy_nodes")
	_clusterOverviewCache.FaultyNodes = field.NewInt32(tableName, "faulty_nodes")
	_clusterOverviewCache.FullyIdleNodes = field.NewInt32(tableName, "fully_idle_nodes")
	_clusterOverviewCache.PartiallyIdleNodes = field.NewInt32(tableName, "partially_idle_nodes")
	_clusterOverviewCache.BusyNodes = field.NewInt32(tableName, "busy_nodes")
	_clusterOverviewCache.AllocationRate = field.NewFloat64(tableName, "allocation_rate")
	_clusterOverviewCache.Utilization = field.NewFloat64(tableName, "utilization")
	_clusterOverviewCache.StorageTotalSpace = field.NewFloat64(tableName, "storage_total_space")
	_clusterOverviewCache.StorageUsedSpace = field.NewFloat64(tableName, "storage_used_space")
	_clusterOverviewCache.StorageUsagePercentage = field.NewFloat64(tableName, "storage_usage_percentage")
	_clusterOverviewCache.StorageTotalInodes = field.NewFloat64(tableName, "storage_total_inodes")
	_clusterOverviewCache.StorageUsedInodes = field.NewFloat64(tableName, "storage_used_inodes")
	_clusterOverviewCache.StorageInodesUsagePercentage = field.NewFloat64(tableName, "storage_inodes_usage_percentage")
	_clusterOverviewCache.StorageReadBandwidth = field.NewFloat64(tableName, "storage_read_bandwidth")
	_clusterOverviewCache.StorageWriteBandwidth = field.NewFloat64(tableName, "storage_write_bandwidth")
	_clusterOverviewCache.RdmaTotalTx = field.NewFloat64(tableName, "rdma_total_tx")
	_clusterOverviewCache.RdmaTotalRx = field.NewFloat64(tableName, "rdma_total_rx")
	_clusterOverviewCache.CreatedAt = field.NewTime(tableName, "created_at")
	_clusterOverviewCache.UpdatedAt = field.NewTime(tableName, "updated_at")

	_clusterOverviewCache.fillFieldMap()

	return _clusterOverviewCache
}

type clusterOverviewCache struct {
	clusterOverviewCacheDo clusterOverviewCacheDo

	ALL                          field.Asterisk
	ID                           field.Int32
	ClusterName                  field.String // Name of the cluster
	TotalNodes                   field.Int32  // Total number of GPU nodes
	HealthyNodes                 field.Int32
	FaultyNodes                  field.Int32
	FullyIdleNodes               field.Int32
	PartiallyIdleNodes           field.Int32
	BusyNodes                    field.Int32
	AllocationRate               field.Float64 // GPU allocation rate (0-100)
	Utilization                  field.Float64 // GPU utilization rate (0-100)
	StorageTotalSpace            field.Float64
	StorageUsedSpace             field.Float64
	StorageUsagePercentage       field.Float64
	StorageTotalInodes           field.Float64
	StorageUsedInodes            field.Float64
	StorageInodesUsagePercentage field.Float64
	StorageReadBandwidth         field.Float64
	StorageWriteBandwidth        field.Float64
	RdmaTotalTx                  field.Float64
	RdmaTotalRx                  field.Float64
	CreatedAt                    field.Time
	UpdatedAt                    field.Time

	fieldMap map[string]field.Expr
}

func (c clusterOverviewCache) Table(newTableName string) *clusterOverviewCache {
	c.clusterOverviewCacheDo.UseTable(newTableName)
	return c.updateTableName(newTableName)
}

func (c clusterOverviewCache) As(alias string) *clusterOverviewCache {
	c.clusterOverviewCacheDo.DO = *(c.clusterOverviewCacheDo.As(alias).(*gen.DO))
	return c.updateTableName(alias)
}

func (c *clusterOverviewCache) updateTableName(table string) *clusterOverviewCache {
	c.ALL = field.NewAsterisk(table)
	c.ID = field.NewInt32(table, "id")
	c.ClusterName = field.NewString(table, "cluster_name")
	c.TotalNodes = field.NewInt32(table, "total_nodes")
	c.HealthyNodes = field.NewInt32(table, "healthy_nodes")
	c.FaultyNodes = field.NewInt32(table, "faulty_nodes")
	c.FullyIdleNodes = field.NewInt32(table, "fully_idle_nodes")
	c.PartiallyIdleNodes = field.NewInt32(table, "partially_idle_nodes")
	c.BusyNodes = field.NewInt32(table, "busy_nodes")
	c.AllocationRate = field.NewFloat64(table, "allocation_rate")
	c.Utilization = field.NewFloat64(table, "utilization")
	c.StorageTotalSpace = field.NewFloat64(table, "storage_total_space")
	c.StorageUsedSpace = field.NewFloat64(table, "storage_used_space")
	c.StorageUsagePercentage = field.NewFloat64(table, "storage_usage_percentage")
	c.StorageTotalInodes = field.NewFloat64(table, "storage_total_inodes")
	c.StorageUsedInodes = field.NewFloat64(table, "storage_used_inodes")
	c.StorageInodesUsagePercentage = field.NewFloat64(table, "storage_inodes_usage_percentage")
	c.StorageReadBandwidth = field.NewFloat64(table, "storage_read_bandwidth")
	c.StorageWriteBandwidth = field.NewFloat64(table, "storage_write_bandwidth")
	c.RdmaTotalTx = field.NewFloat64(table, "rdma_total_tx")
	c.RdmaTotalRx = field.NewFloat64(table, "rdma_total_rx")
	c.CreatedAt = field.NewTime(table, "created_at")
	c.UpdatedAt = field.NewTime(table, "updated_at")

	c.fillFieldMap()

	return c
}

func (c *clusterOverviewCache) WithContext(ctx context.Context) *clusterOverviewCacheDo {
	return c.clusterOverviewCacheDo.WithContext(ctx)
}

func (c clusterOverviewCache) TableName() string { return c.clusterOverviewCacheDo.TableName() }

func (c clusterOverviewCache) Alias() string { return c.clusterOverviewCacheDo.Alias() }

func (c clusterOverviewCache) Columns(cols ...field.Expr) gen.Columns {
	return c.clusterOverviewCacheDo.Columns(cols...)
}

func (c *clusterOverviewCache) GetFieldByName(fieldName string) (field.OrderExpr, bool) {
	_f, ok := c.fieldMap[fieldName]
	if !ok || _f == nil {
		return nil, false
	}
	_oe, ok := _f.(field.OrderExpr)
	return _oe, ok
}

func (c *clusterOverviewCache) fillFieldMap() {
	c.fieldMap = make(map[string]field.Expr, 22)
	c.fieldMap["id"] = c.ID
	c.fieldMap["cluster_name"] = c.ClusterName
	c.fieldMap["total_nodes"] = c.TotalNodes
	c.fieldMap["healthy_nodes"] = c.HealthyNodes
	c.fieldMap["faulty_nodes"] = c.FaultyNodes
	c.fieldMap["fully_idle_nodes"] = c.FullyIdleNodes
	c.fieldMap["partially_idle_nodes"] = c.PartiallyIdleNodes
	c.fieldMap["busy_nodes"] = c.BusyNodes
	c.fieldMap["allocation_rate"] = c.AllocationRate
	c.fieldMap["utilization"] = c.Utilization
	c.fieldMap["storage_total_space"] = c.StorageTotalSpace
	c.fieldMap["storage_used_space"] = c.StorageUsedSpace
	c.fieldMap["storage_usage_percentage"] = c.StorageUsagePercentage
	c.fieldMap["storage_total_inodes"] = c.StorageTotalInodes
	c.fieldMap["storage_used_inodes"] = c.StorageUsedInodes
	c.fieldMap["storage_inodes_usage_percentage"] = c.StorageInodesUsagePercentage
	c.fieldMap["storage_read_bandwidth"] = c.StorageReadBandwidth
	c.fieldMap["storage_write_bandwidth"] = c.StorageWriteBandwidth
	c.fieldMap["rdma_total_tx"] = c.RdmaTotalTx
	c.fieldMap["rdma_total_rx"] = c.RdmaTotalRx
	c.fieldMap["created_at"] = c.CreatedAt
	c.fieldMap["updated_at"] = c.UpdatedAt
}

func (c clusterOverviewCache) clone(db *gorm.DB) clusterOverviewCache {
	c.clusterOverviewCacheDo.ReplaceConnPool(db.Statement.ConnPool)
	return c
}

func (c clusterOverviewCache) replaceDB(db *gorm.DB) clusterOverviewCache {
	c.clusterOverviewCacheDo.ReplaceDB(db)
	return c
}

type clusterOverviewCacheDo struct{ gen.DO }

func (c clusterOverviewCacheDo) Debug() *clusterOverviewCacheDo {
	return c.withDO(c.DO.Debug())
}

func (c clusterOverviewCacheDo) WithContext(ctx context.Context) *clusterOverviewCacheDo {
	return c.withDO(c.DO.WithContext(ctx))
}

func (c clusterOverviewCacheDo) ReadDB() *clusterOverviewCacheDo {
	return c.Clauses(dbresolver.Read)
}

func (c clusterOverviewCacheDo) WriteDB() *clusterOverviewCacheDo {
	return c.Clauses(dbresolver.Write)
}

func (c clusterOverviewCacheDo) Session(config *gorm.Session) *clusterOverviewCacheDo {
	return c.withDO(c.DO.Session(config))
}

func (c clusterOverviewCacheDo) Clauses(conds ...clause.Expression) *clusterOverviewCacheDo {
	return c.withDO(c.DO.Clauses(conds...))
}

func (c clusterOverviewCacheDo) Returning(value interface{}, columns ...string) *clusterOverviewCacheDo {
	return c.withDO(c.DO.Returning(value, columns...))
}

func (c clusterOverviewCacheDo) Not(conds ...gen.Condition) *clusterOverviewCacheDo {
	return c.withDO(c.DO.Not(conds...))
}

func (c clusterOverviewCacheDo) Or(conds ...gen.Condition) *clusterOverviewCacheDo {
	return c.withDO(c.DO.Or(conds...))
}

func (c clusterOverviewCacheDo) Select(conds ...field.Expr) *clusterOverviewCacheDo {
	return c.withDO(c.DO.Select(conds...))
}

func (c clusterOverviewCacheDo) Where(conds ...gen.Condition) *clusterOverviewCacheDo {
	return c.withDO(c.DO.Where(conds...))
}

func (c clusterOverviewCacheDo) Order(conds ...field.Expr) *clusterOverviewCacheDo {
	return c.withDO(c.DO.Order(conds...))
}

func (c clusterOverviewCacheDo) Distinct(cols ...field.Expr) *clusterOverviewCacheDo {
	return c.withDO(c.DO.Distinct(cols...))
}

func (c clusterOverviewCacheDo) Omit(cols ...field.Expr) *clusterOverviewCacheDo {
	return c.withDO(c.DO.Omit(cols...))
}

func (c clusterOverviewCacheDo) Join(table schema.Tabler, on ...field.Expr) *clusterOverviewCacheDo {
	return c.withDO(c.DO.Join(table, on...))
}

func (c clusterOverviewCacheDo) LeftJoin(table schema.Tabler, on ...field.Expr) *clusterOverviewCacheDo {
	return c.withDO(c.DO.LeftJoin(table, on...))
}

func (c clusterOverviewCacheDo) RightJoin(table schema.Tabler, on ...field.Expr) *clusterOverviewCacheDo {
	return c.withDO(c.DO.RightJoin(table, on...))
}

func (c clusterOverviewCacheDo) Group(cols ...field.Expr) *clusterOverviewCacheDo {
	return c.withDO(c.DO.Group(cols...))
}

func (c clusterOverviewCacheDo) Having(conds ...gen.Condition) *clusterOverviewCacheDo {
	return c.withDO(c.DO.Having(conds...))
}

func (c clusterOverviewCacheDo) Limit(limit int) *clusterOverviewCacheDo {
	return c.withDO(c.DO.Limit(limit))
}

func (c clusterOverviewCacheDo) Offset(offset int) *clusterOverviewCacheDo {
	return c.withDO(c.DO.Offset(offset))
}

func (c clusterOverviewCacheDo) Scopes(funcs ...func(gen.Dao) gen.Dao) *clusterOverviewCacheDo {
	return c.withDO(c.DO.Scopes(funcs...))
}

func (c clusterOverviewCacheDo) Unscoped() *clusterOverviewCacheDo {
	return c.withDO(c.DO.Unscoped())
}

func (c clusterOverviewCacheDo) Create(values ...*model.ClusterOverviewCache) error {
	if len(values) == 0 {
		return nil
	}
	return c.DO.Create(values)
}

func (c clusterOverviewCacheDo) CreateInBatches(values []*model.ClusterOverviewCache, batchSize int) error {
	return c.DO.CreateInBatches(values, batchSize)
}

// Save : !!! underlying implementation is different with GORM
// The method is equivalent to executing the statement: db.Clauses(clause.OnConflict{UpdateAll: true}).Create(values)
func (c clusterOverviewCacheDo) Save(values ...*model.ClusterOverviewCache) error {
	if len(values) == 0 {
		return nil
	}
	return c.DO.Save(values)
}

func (c clusterOverviewCacheDo) First() (*model.ClusterOverviewCache, error) {
	if result, err := c.DO.First(); err != nil {
		return nil, err
	} else {
		return result.(*model.ClusterOverviewCache), nil
	}
}

func (c clusterOverviewCacheDo) Take() (*model.ClusterOverviewCache, error) {
	if result, err := c.DO.Take(); err != nil {
		return nil, err
	} else {
		return result.(*model.ClusterOverviewCache), nil
	}
}

func (c clusterOverviewCacheDo) Last() (*model.ClusterOverviewCache, error) {
	if result, err := c.DO.Last(); err != nil {
		return nil, err
	} else {
		return result.(*model.ClusterOverviewCache), nil
	}
}

func (c clusterOverviewCacheDo) Find() ([]*model.ClusterOverviewCache, error) {
	result, err := c.DO.Find()
	return result.([]*model.ClusterOverviewCache), err
}

func (c clusterOverviewCacheDo) FindInBatch(batchSize int, fc func(tx gen.Dao, batch int) error) (results []*model.ClusterOverviewCache, err error) {
	buf := make([]*model.ClusterOverviewCache, 0, batchSize)
	err = c.DO.FindInBatches(&buf, batchSize, func(tx gen.Dao, batch int) error {
		defer func() { results = append(results, buf...) }()
		return fc(tx, batch)
	})
	return results, err
}

func (c clusterOverviewCacheDo) FindInBatches(result *[]*model.ClusterOverviewCache, batchSize int, fc func(tx gen.Dao, batch int) error) error {
	return c.DO.FindInBatches(result, batchSize, fc)
}

func (c clusterOverviewCacheDo) Attrs(attrs ...field.AssignExpr) *clusterOverviewCacheDo {
	return c.withDO(c.DO.Attrs(attrs...))
}

func (c clusterOverviewCacheDo) Assign(attrs ...field.AssignExpr) *clusterOverviewCacheDo {
	return c.withDO(c.DO.Assign(attrs...))
}

func (c clusterOverviewCacheDo) Joins(fields ...field.RelationField) *clusterOverviewCacheDo {
	for _, _f := range fields {
		c = *c.withDO(c.DO.Joins(_f))
	}
	return &c
}

func (c clusterOverviewCacheDo) Preload(fields ...field.RelationField) *clusterOverviewCacheDo {
	for _, _f := range fields {
		c = *c.withDO(c.DO.Preload(_f))
	}
	return &c
}

func (c clusterOverviewCacheDo) FirstOrInit() (*model.ClusterOverviewCache, error) {
	if result, err := c.DO.FirstOrInit(); err != nil {
		return nil, err
	} else {
		return result.(*model.ClusterOverviewCache), nil
	}
}

func (c clusterOverviewCacheDo) FirstOrCreate() (*model.ClusterOverviewCache, error) {
	if result, err := c.DO.FirstOrCreate(); err != nil {
		return nil, err
	} else {
		return result.(*model.ClusterOverviewCache), nil
	}
}

func (c clusterOverviewCacheDo) FindByPage(offset int, limit int) (result []*model.ClusterOverviewCache, count int64, err error) {
	result, err = c.Offset(offset).Limit(limit).Find()
	if err != nil {
		return
	}

	if size := len(result); 0 < limit && 0 < size && size < limit {
		count = int64(size + offset)
		return
	}

	count, err = c.Offset(-1).Limit(-1).Count()
	return
}

func (c clusterOverviewCacheDo) ScanByPage(result interface{}, offset int, limit int) (count int64, err error) {
	count, err = c.Count()
	if err != nil {
		return
	}

	err = c.Offset(offset).Limit(limit).Scan(result)
	return
}

func (c clusterOverviewCacheDo) Scan(result interface{}) (err error) {
	return c.DO.Scan(result)
}

func (c clusterOverviewCacheDo) Delete(models ...*model.ClusterOverviewCache) (result gen.ResultInfo, err error) {
	return c.DO.Delete(models)
}

func (c *clusterOverviewCacheDo) withDO(do gen.Dao) *clusterOverviewCacheDo {
	c.DO = *do.(*gen.DO)
	return c
}
