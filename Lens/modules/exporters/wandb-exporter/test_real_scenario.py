#!/usr/bin/env python3
"""
WandB Exporter çœŸå®åœºæ™¯æµ‹è¯•ç¨‹åº

è¿™ä¸ªæµ‹è¯•ç¨‹åºæ¨¡æ‹ŸçœŸå®çš„è®­ç»ƒåœºæ™¯ï¼Œå…¨é¢æµ‹è¯• wandb-exporter çš„å„é¡¹åŠŸèƒ½ï¼š
1. çœŸå®çš„ W&B API è°ƒç”¨ï¼ˆinit, log, finishï¼‰
2. æœ¬åœ°æ–‡ä»¶ä¿å­˜å’ŒæŒ‡æ ‡å¢å¼º
3. å¼‚æ­¥ API ä¸ŠæŠ¥ï¼ˆæ¡†æ¶æ£€æµ‹ã€è®­ç»ƒæŒ‡æ ‡ï¼‰
4. åˆ†å¸ƒå¼è®­ç»ƒåœºæ™¯ï¼ˆå¤šèŠ‚ç‚¹ã€å¤šGPUï¼‰
5. é”™è¯¯å¤„ç†å’Œè¾¹ç¼˜æƒ…å†µ

è¿è¡Œæ–¹å¼ï¼š
    python test_real_scenario.py [--scenario SCENARIO]

å‚æ•°ï¼š
    --scenario: æµ‹è¯•åœºæ™¯ï¼Œå¯é€‰å€¼ï¼š
        - basic: åŸºç¡€å•æœºè®­ç»ƒåœºæ™¯ï¼ˆé»˜è®¤ï¼‰
        - distributed: åˆ†å¸ƒå¼è®­ç»ƒåœºæ™¯
        - api_reporting: API ä¸ŠæŠ¥åœºæ™¯
        - stress: å‹åŠ›æµ‹è¯•åœºæ™¯
        - all: è¿è¡Œæ‰€æœ‰åœºæ™¯
"""

import os
import sys
import time
import json
import tempfile
import shutil
import argparse
from pathlib import Path
from typing import Dict, List, Any, Optional
import random

# æµ‹è¯•ç»“æœæ”¶é›†
class TestResults:
    """æµ‹è¯•ç»“æœæ”¶é›†å™¨"""
    
    def __init__(self):
        self.scenarios = []
        self.current_scenario = None
        self.start_time = time.time()
    
    def start_scenario(self, name: str, description: str):
        """å¼€å§‹ä¸€ä¸ªæµ‹è¯•åœºæ™¯"""
        self.current_scenario = {
            "name": name,
            "description": description,
            "tests": [],
            "start_time": time.time(),
            "status": "running",
        }
        print(f"\n{'='*70}")
        print(f"æµ‹è¯•åœºæ™¯: {name}")
        print(f"æè¿°: {description}")
        print(f"{'='*70}\n")
    
    def add_test(self, test_name: str, passed: bool, message: str = "", details: Any = None):
        """æ·»åŠ æµ‹è¯•ç»“æœ"""
        if self.current_scenario is None:
            return
        
        status = "âœ“ é€šè¿‡" if passed else "âœ— å¤±è´¥"
        print(f"  [{status}] {test_name}")
        if message:
            print(f"      â†’ {message}")
        
        self.current_scenario["tests"].append({
            "name": test_name,
            "passed": passed,
            "message": message,
            "details": details,
        })
    
    def end_scenario(self):
        """ç»“æŸå½“å‰æµ‹è¯•åœºæ™¯"""
        if self.current_scenario is None:
            return
        
        self.current_scenario["end_time"] = time.time()
        self.current_scenario["duration"] = self.current_scenario["end_time"] - self.current_scenario["start_time"]
        
        passed_count = sum(1 for t in self.current_scenario["tests"] if t["passed"])
        total_count = len(self.current_scenario["tests"])
        
        if passed_count == total_count:
            self.current_scenario["status"] = "passed"
        else:
            self.current_scenario["status"] = "failed"
        
        print(f"\nåœºæ™¯ç»“æœ: {passed_count}/{total_count} æµ‹è¯•é€šè¿‡")
        print(f"è€—æ—¶: {self.current_scenario['duration']:.2f} ç§’\n")
        
        self.scenarios.append(self.current_scenario)
        self.current_scenario = None
    
    def print_summary(self):
        """æ‰“å°æµ‹è¯•æ€»ç»“"""
        print("\n" + "="*70)
        print("æµ‹è¯•æ€»ç»“")
        print("="*70 + "\n")
        
        total_scenarios = len(self.scenarios)
        passed_scenarios = sum(1 for s in self.scenarios if s["status"] == "passed")
        
        for scenario in self.scenarios:
            status_symbol = "âœ“" if scenario["status"] == "passed" else "âœ—"
            passed = sum(1 for t in scenario["tests"] if t["passed"])
            total = len(scenario["tests"])
            
            print(f"{status_symbol} {scenario['name']}: {passed}/{total} æµ‹è¯•é€šè¿‡ "
                  f"({scenario['duration']:.2f}s)")
        
        print(f"\nåœºæ™¯ç»Ÿè®¡: {passed_scenarios}/{total_scenarios} åœºæ™¯é€šè¿‡")
        print(f"æ€»è€—æ—¶: {time.time() - self.start_time:.2f} ç§’\n")
        
        if passed_scenarios == total_scenarios:
            print("ğŸ‰ æ‰€æœ‰æµ‹è¯•åœºæ™¯é€šè¿‡ï¼\n")
            return 0
        else:
            print(f"âš ï¸  {total_scenarios - passed_scenarios} ä¸ªåœºæ™¯å¤±è´¥\n")
            return 1


# å…¨å±€æµ‹è¯•ç»“æœ
test_results = TestResults()


def setup_environment(api_url: Optional[str] = None, enable_api: bool = True, tmpdir: Optional[str] = None, force_hook: bool = False):
    """è®¾ç½®æµ‹è¯•ç¯å¢ƒå˜é‡"""
    if tmpdir is None:
        tmpdir = tempfile.mkdtemp(prefix="wandb_test_")
    
    # åŸºç¡€é…ç½®
    os.environ["PRIMUS_LENS_WANDB_HOOK"] = "true"
    os.environ["PRIMUS_LENS_WANDB_ENHANCE_METRICS"] = "true"
    os.environ["PRIMUS_LENS_WANDB_SAVE_LOCAL"] = "true"
    os.environ["PRIMUS_LENS_WANDB_OUTPUT_PATH"] = tmpdir
    
    # å¦‚æœéœ€è¦å¼ºåˆ¶åŠ è½½åŠ«æŒï¼ˆç”¨äºæµ‹è¯•ç¯å¢ƒï¼‰
    if force_hook and 'wandb' not in sys.modules:
        try:
            # æ˜¾å¼å¯¼å…¥åŠ«æŒæ¨¡å—ï¼ˆå¿…é¡»åœ¨ wandb ä¹‹å‰å¯¼å…¥ï¼‰
            src_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'src')
            if src_path not in sys.path:
                sys.path.insert(0, src_path)
            # å¯¼å…¥ wandb_hook æ¨¡å—ä¼šè‡ªåŠ¨æ³¨å†Œ import hook
            import primus_lens_wandb_exporter.wandb_hook
        except ImportError as e:
            print(f"  è­¦å‘Š: æ— æ³•åŠ è½½åŠ«æŒæ¨¡å—: {e}")
        except Exception as e:
            print(f"  è­¦å‘Š: åŠ è½½åŠ«æŒæ¨¡å—æ—¶å‡ºé”™: {e}")
    
    # WandB é…ç½®ï¼ˆä½¿ç”¨ç¦»çº¿æ¨¡å¼ï¼Œé¿å…çœŸå®ä¸ŠæŠ¥åˆ° W&Bï¼‰
    os.environ["WANDB_MODE"] = "offline"
    os.environ["WANDB_SILENT"] = "true"
    
    # API ä¸ŠæŠ¥é…ç½®
    if enable_api:
        os.environ["PRIMUS_LENS_WANDB_API_REPORTING"] = "true"
        if api_url:
            os.environ["PRIMUS_LENS_API_BASE_URL"] = api_url
        else:
            # ä½¿ç”¨æµ‹è¯• URLï¼ˆä¸ä¼šçœŸå®å‘é€ï¼Œä½†ä¼šè®°å½•ï¼‰
            os.environ["PRIMUS_LENS_API_BASE_URL"] = "http://localhost:18080/api/v1"
        
        # è®¾ç½®å¿…éœ€çš„æ ‡è¯†
        os.environ["WORKLOAD_UID"] = "test-workload-12345"
        os.environ["POD_NAME"] = "test-pod"
        os.environ["POD_NAMESPACE"] = "default"
    else:
        os.environ["PRIMUS_LENS_WANDB_API_REPORTING"] = "false"
    
    return tmpdir


def cleanup_environment(tmpdir: str):
    """æ¸…ç†æµ‹è¯•ç¯å¢ƒ"""
    try:
        if os.path.exists(tmpdir):
            shutil.rmtree(tmpdir)
    except Exception as e:
        print(f"æ¸…ç†ä¸´æ—¶ç›®å½•å¤±è´¥: {e}")
    
    # æ¸…ç†åˆ†å¸ƒå¼è®­ç»ƒç›¸å…³çš„ç¯å¢ƒå˜é‡
    for var in ['RANK', 'LOCAL_RANK', 'NODE_RANK', 'WORLD_SIZE']:
        os.environ.pop(var, None)


def verify_metrics_file(tmpdir: str, node_rank: int = 0, local_rank: int = 0) -> tuple:
    """éªŒè¯æŒ‡æ ‡æ–‡ä»¶æ˜¯å¦æ­£ç¡®ç”Ÿæˆ"""
    metrics_file = os.path.join(tmpdir, f"node_{node_rank}", f"rank_{local_rank}", "wandb_metrics.jsonl")
    
    if not os.path.exists(metrics_file):
        return False, f"æŒ‡æ ‡æ–‡ä»¶ä¸å­˜åœ¨: {metrics_file}"
    
    try:
        with open(metrics_file, 'r') as f:
            lines = f.readlines()
        
        if not lines:
            return False, "æŒ‡æ ‡æ–‡ä»¶ä¸ºç©º"
        
        # éªŒè¯ JSON æ ¼å¼
        metrics_count = 0
        for line in lines:
            try:
                data = json.loads(line)
                if "timestamp" not in data or "data" not in data:
                    return False, "æŒ‡æ ‡æ ¼å¼ä¸æ­£ç¡®ï¼ˆç¼ºå°‘å¿…éœ€å­—æ®µï¼‰"
                metrics_count += 1
            except json.JSONDecodeError:
                return False, f"JSON æ ¼å¼é”™è¯¯: {line[:100]}"
        
        return True, f"æ‰¾åˆ° {metrics_count} æ¡æŒ‡æ ‡è®°å½•"
    
    except Exception as e:
        return False, f"è¯»å–æŒ‡æ ‡æ–‡ä»¶å¤±è´¥: {e}"


def verify_metrics_enhanced(tmpdir: str, node_rank: int = 0, local_rank: int = 0) -> tuple:
    """éªŒè¯æŒ‡æ ‡æ˜¯å¦åŒ…å«ç³»ç»Ÿå¢å¼ºä¿¡æ¯"""
    metrics_file = os.path.join(tmpdir, f"node_{node_rank}", f"rank_{local_rank}", "wandb_metrics.jsonl")
    
    try:
        with open(metrics_file, 'r') as f:
            line = f.readline()
        
        data = json.loads(line)
        metrics_data = data.get("data", {})
        
        # æ£€æŸ¥ Primus Lens æ ‡è®°
        if "_primus_lens_enabled" not in metrics_data:
            return False, "ç¼ºå°‘ Primus Lens æ ‡è®°"
        
        # æ£€æŸ¥ç³»ç»ŸæŒ‡æ ‡ï¼ˆå¦‚æœ psutil å¯ç”¨ï¼‰
        try:
            import psutil
            if "_primus_sys_cpu_percent" not in metrics_data:
                return False, "ç¼ºå°‘ CPU ç³»ç»ŸæŒ‡æ ‡"
            if "_primus_sys_memory_percent" not in metrics_data:
                return False, "ç¼ºå°‘å†…å­˜ç³»ç»ŸæŒ‡æ ‡"
        except ImportError:
            pass
        
        return True, "æŒ‡æ ‡å¢å¼ºæ­£å¸¸"
    
    except Exception as e:
        return False, f"éªŒè¯å¤±è´¥: {e}"


# ========== æµ‹è¯•åœºæ™¯ ==========

def test_scenario_basic():
    """åœºæ™¯1: åŸºç¡€å•æœºè®­ç»ƒåœºæ™¯"""
    test_results.start_scenario(
        "åŸºç¡€å•æœºè®­ç»ƒ",
        "æµ‹è¯•åŸºæœ¬çš„ W&B åŠ«æŒã€æŒ‡æ ‡ä¿å­˜å’Œå¢å¼ºåŠŸèƒ½"
    )
    
    tmpdir = None
    try:
        # è®¾ç½®ç¯å¢ƒï¼ˆå¼ºåˆ¶åŠ è½½åŠ«æŒï¼‰
        tmpdir = setup_environment(enable_api=False, force_hook=True)
        
        # å¯¼å…¥ wandbï¼ˆè§¦å‘åŠ«æŒï¼‰
        import wandb
        
        # æµ‹è¯•1: éªŒè¯åŠ«æŒæ˜¯å¦æˆåŠŸ
        is_patched = hasattr(wandb, '_primus_lens_patched')
        test_results.add_test(
            "WandB åŠ«æŒ",
            is_patched,
            "WandB å·²è¢« Primus Lens æˆåŠŸåŠ«æŒ" if is_patched else "WandB æœªè¢«åŠ«æŒ"
        )
        
        # æµ‹è¯•2: åˆå§‹åŒ– wandb
        try:
            run = wandb.init(
                project="primus-test",
                name="basic-test",
                config={"lr": 0.001, "batch_size": 32}
            )
            test_results.add_test(
                "WandB åˆå§‹åŒ–",
                run is not None,
                f"Run ID: {run.id if run else 'None'}"
            )
        except Exception as e:
            test_results.add_test("WandB åˆå§‹åŒ–", False, f"åˆå§‹åŒ–å¤±è´¥: {e}")
            return
        
        # æµ‹è¯•3: è®°å½•æŒ‡æ ‡
        num_steps = 10
        try:
            print(f"\n  DEBUG: wandb.log ç±»å‹: {type(wandb.log)}")
            print(f"  DEBUG: wandb.log åç§°: {wandb.log.__name__ if hasattr(wandb.log, '__name__') else 'N/A'}")
            for step in range(num_steps):
                print(f"  DEBUG: è°ƒç”¨ wandb.log, step={step}")
                wandb.log({
                    "loss": 1.0 - (step * 0.05),
                    "accuracy": 0.5 + (step * 0.04),
                    "step": step,
                }, step=step)
            test_results.add_test(
                "æŒ‡æ ‡è®°å½•",
                True,
                f"æˆåŠŸè®°å½• {num_steps} æ­¥æŒ‡æ ‡"
            )
        except Exception as e:
            test_results.add_test("æŒ‡æ ‡è®°å½•", False, f"è®°å½•å¤±è´¥: {e}")
        
        # å®Œæˆ run
        wandb.finish()
        
        # ç­‰å¾…æ–‡ä»¶å†™å…¥
        time.sleep(0.5)
        
        # DEBUG: æŸ¥çœ‹å®é™…ç”Ÿæˆçš„ç›®å½•ç»“æ„
        print(f"\n  DEBUG: ä¸´æ—¶ç›®å½•: {tmpdir}")
        if os.path.exists(tmpdir):
            for root, dirs, files in os.walk(tmpdir):
                level = root.replace(tmpdir, '').count(os.sep)
                indent = ' ' * 4 * level
                print(f'  DEBUG: {indent}{os.path.basename(root)}/')
                subindent = ' ' * 4 * (level + 1)
                for file in files:
                    print(f'  DEBUG: {subindent}{file}')
        
        # æµ‹è¯•4: éªŒè¯æŒ‡æ ‡æ–‡ä»¶ï¼ˆä½¿ç”¨ rank_-1ï¼Œå› ä¸ºæœªè®¾ç½® RANK ç¯å¢ƒå˜é‡ï¼‰
        success, message = verify_metrics_file(tmpdir, node_rank=0, local_rank=-1)
        test_results.add_test("æŒ‡æ ‡æ–‡ä»¶ç”Ÿæˆ", success, message)
        
        # æµ‹è¯•5: éªŒè¯æŒ‡æ ‡å¢å¼º
        if success:
            success, message = verify_metrics_enhanced(tmpdir, node_rank=0, local_rank=-1)
            test_results.add_test("æŒ‡æ ‡å¢å¼º", success, message)
    
    finally:
        test_results.end_scenario()
        if tmpdir:
            cleanup_environment(tmpdir)


def test_scenario_distributed():
    """åœºæ™¯2: åˆ†å¸ƒå¼è®­ç»ƒåœºæ™¯"""
    test_results.start_scenario(
        "åˆ†å¸ƒå¼è®­ç»ƒ",
        "æµ‹è¯•å¤šèŠ‚ç‚¹ã€å¤šGPU åœºæ™¯ä¸‹çš„æŒ‡æ ‡ä¿å­˜å’Œè·¯å¾„éš”ç¦»"
    )
    
    tmpdir = None
    try:
        tmpdir = setup_environment(enable_api=False, force_hook=True)
        
        # æ¨¡æ‹Ÿ 2 ä¸ªèŠ‚ç‚¹ï¼Œæ¯ä¸ªèŠ‚ç‚¹ 2 ä¸ª GPU
        nodes = 2
        ranks_per_node = 2
        
        for node in range(nodes):
            for local_rank in range(ranks_per_node):
                # è®¾ç½®åˆ†å¸ƒå¼ç¯å¢ƒå˜é‡
                global_rank = node * ranks_per_node + local_rank
                os.environ["NODE_RANK"] = str(node)
                os.environ["LOCAL_RANK"] = str(local_rank)
                os.environ["RANK"] = str(global_rank)
                os.environ["WORLD_SIZE"] = str(nodes * ranks_per_node)
                
                # å¯¼å…¥ wandbï¼ˆç¬¬ä¸€æ¬¡å¾ªç¯æ—¶å¯¼å…¥ï¼Œä¹‹åå¤ç”¨ï¼‰
                if 'wandb' not in sys.modules:
                    import wandb
                else:
                    import wandb
                
                # åˆå§‹åŒ–ï¼ˆç¯å¢ƒå˜é‡ä¼šåœ¨ init æ—¶è¢«è¯»å–ï¼‰
                run = wandb.init(
                    project="primus-distributed-test",
                    name=f"node{node}-rank{local_rank}",
                    config={"node": node, "local_rank": local_rank},
                    reinit=True  # å…è®¸åœ¨åŒä¸€è¿›ç¨‹ä¸­å¤šæ¬¡ init
                )
                
                # è®°å½•ä¸€äº›æŒ‡æ ‡
                for step in range(5):
                    wandb.log({
                        "loss": 1.0 - (step * 0.1),
                        "node": node,
                        "rank": local_rank,
                    }, step=step)
                
                wandb.finish()
        
        # ç­‰å¾…æ–‡ä»¶å†™å…¥
        time.sleep(1.0)
        
        # éªŒè¯æ‰€æœ‰èŠ‚ç‚¹å’Œ rank çš„æ–‡ä»¶
        all_success = True
        for node in range(nodes):
            for local_rank in range(ranks_per_node):
                success, message = verify_metrics_file(tmpdir, node, local_rank)
                if not success:
                    all_success = False
                    test_results.add_test(
                        f"èŠ‚ç‚¹{node} Rank{local_rank} æŒ‡æ ‡æ–‡ä»¶",
                        False,
                        message
                    )
        
        if all_success:
            test_results.add_test(
                "æ‰€æœ‰èŠ‚ç‚¹æŒ‡æ ‡æ–‡ä»¶",
                True,
                f"æˆåŠŸç”Ÿæˆ {nodes}x{ranks_per_node} ä¸ªèŠ‚ç‚¹çš„æŒ‡æ ‡æ–‡ä»¶"
            )
        
        # éªŒè¯æ–‡ä»¶éš”ç¦»ï¼ˆæ¯ä¸ª rank çš„æ–‡ä»¶äº’ä¸å¹²æ‰°ï¼‰
        test_results.add_test(
            "æ–‡ä»¶è·¯å¾„éš”ç¦»",
            all_success,
            "æ¯ä¸ªèŠ‚ç‚¹/rank çš„æŒ‡æ ‡ä¿å­˜åˆ°ç‹¬ç«‹ç›®å½•"
        )
    
    finally:
        test_results.end_scenario()
        if tmpdir:
            cleanup_environment(tmpdir)


def test_scenario_api_reporting():
    """åœºæ™¯3: API å¼‚æ­¥ä¸ŠæŠ¥åœºæ™¯"""
    test_results.start_scenario(
        "API å¼‚æ­¥ä¸ŠæŠ¥",
        "æµ‹è¯•æ¡†æ¶æ£€æµ‹å’Œè®­ç»ƒæŒ‡æ ‡çš„å¼‚æ­¥ API ä¸ŠæŠ¥åŠŸèƒ½"
    )
    
    tmpdir = None
    try:
        tmpdir = setup_environment(enable_api=True, force_hook=True)
        
        # è®¾ç½®æ¡†æ¶ç‰¹å¾ç¯å¢ƒå˜é‡
        os.environ["PRIMUS_CONFIG"] = "/config/primus.yaml"
        os.environ["PRIMUS_VERSION"] = "1.2.3"
        
        # å¯¼å…¥ wandbï¼ˆä¸è¦åˆ é™¤æ¨¡å—ï¼Œä¿æŒçŠ¶æ€ï¼‰
        import wandb
        
        # æµ‹è¯•1: éªŒè¯ API ä¸ŠæŠ¥æ¨¡å—æ˜¯å¦å¯ç”¨
        try:
            from primus_lens_wandb_exporter.api_reporter import get_global_reporter
            reporter = get_global_reporter()
            test_results.add_test(
                "API ä¸ŠæŠ¥å™¨åˆå§‹åŒ–",
                reporter is not None,
                "å…¨å±€ä¸ŠæŠ¥å™¨å·²å¯åŠ¨"
            )
        except Exception as e:
            test_results.add_test("API ä¸ŠæŠ¥å™¨åˆå§‹åŒ–", False, f"åˆå§‹åŒ–å¤±è´¥: {e}")
            return
        
        # æµ‹è¯•2: åˆå§‹åŒ– wandbï¼ˆè§¦å‘æ¡†æ¶æ£€æµ‹ä¸ŠæŠ¥ï¼‰
        try:
            run = wandb.init(
                project="primus-api-test",
                name="api-reporting-test",
                config={
                    "framework": "primus",
                    "model": "llama-7b",
                    "learning_rate": 0.001,
                },
                reinit=True  # å…è®¸åœ¨åŒä¸€è¿›ç¨‹ä¸­å¤šæ¬¡ init
            )
            test_results.add_test(
                "æ¡†æ¶æ£€æµ‹è§¦å‘",
                run is not None,
                "wandb.init() è§¦å‘æ¡†æ¶æ£€æµ‹æ•°æ®é‡‡é›†"
            )
        except Exception as e:
            test_results.add_test("æ¡†æ¶æ£€æµ‹è§¦å‘", False, f"å¤±è´¥: {e}")
            return
        
        # æµ‹è¯•3: è®°å½•æŒ‡æ ‡ï¼ˆè§¦å‘æŒ‡æ ‡ä¸ŠæŠ¥ï¼‰
        num_steps = 20
        try:
            for step in range(num_steps):
                wandb.log({
                    "loss": 2.0 - (step * 0.08),
                    "accuracy": 0.6 + (step * 0.015),
                    "learning_rate": 0.001,
                }, step=step)
            test_results.add_test(
                "è®­ç»ƒæŒ‡æ ‡ä¸ŠæŠ¥",
                True,
                f"è®°å½• {num_steps} æ­¥æŒ‡æ ‡ï¼Œå·²åŠ å…¥ä¸ŠæŠ¥é˜Ÿåˆ—"
            )
        except Exception as e:
            test_results.add_test("è®­ç»ƒæŒ‡æ ‡ä¸ŠæŠ¥", False, f"å¤±è´¥: {e}")
        
        # å®Œæˆ run
        wandb.finish()
        
        # ç­‰å¾…å¼‚æ­¥ä¸ŠæŠ¥å®Œæˆ
        print("  ç­‰å¾…å¼‚æ­¥ä¸ŠæŠ¥å™¨åˆ·æ–°æ•°æ®...")
        time.sleep(3.0)
        
        # æµ‹è¯•4: æ£€æŸ¥ä¸ŠæŠ¥ç»Ÿè®¡
        stats = reporter.stats
        test_results.add_test(
            "ä¸ŠæŠ¥ç»Ÿè®¡",
            True,
            f"æ£€æµ‹æ•°æ®: {stats['detection_sent']}, æŒ‡æ ‡æ‰¹æ¬¡: {stats['metrics_sent']}, é”™è¯¯: {stats['errors']}"
        )
        
        # æµ‹è¯•5: éªŒè¯é˜Ÿåˆ—å·²æ¸…ç©º
        detection_empty = reporter.detection_queue.empty()
        metrics_empty = reporter.metrics_queue.empty()
        test_results.add_test(
            "é˜Ÿåˆ—æ¸…ç©º",
            detection_empty and metrics_empty,
            "æ‰€æœ‰é˜Ÿåˆ—å·²æ¸…ç©º" if (detection_empty and metrics_empty) else "é˜Ÿåˆ—ä¸­ä»æœ‰æ•°æ®"
        )
    
    finally:
        test_results.end_scenario()
        if tmpdir:
            cleanup_environment(tmpdir)


def test_scenario_stress():
    """åœºæ™¯4: å‹åŠ›æµ‹è¯•åœºæ™¯"""
    test_results.start_scenario(
        "å‹åŠ›æµ‹è¯•",
        "æµ‹è¯•å¤§é‡æŒ‡æ ‡è®°å½•æ—¶çš„æ€§èƒ½å’Œç¨³å®šæ€§"
    )
    
    tmpdir = None
    try:
        tmpdir = setup_environment(enable_api=True, force_hook=True)
        
        # å¯¼å…¥ wandbï¼ˆä¸è¦åˆ é™¤æ¨¡å—ï¼‰
        import wandb
        
        # åˆå§‹åŒ–
        run = wandb.init(
            project="primus-stress-test",
            name="stress-test",
            config={"test_type": "stress"},
            reinit=True  # å…è®¸åœ¨åŒä¸€è¿›ç¨‹ä¸­å¤šæ¬¡ init
        )
        
        # å¤§é‡æŒ‡æ ‡è®°å½•
        num_steps = 500
        num_metrics_per_step = 20
        
        start_time = time.time()
        
        try:
            for step in range(num_steps):
                metrics = {
                    f"metric_{i}": random.uniform(0, 100)
                    for i in range(num_metrics_per_step)
                }
                metrics["step"] = step
                wandb.log(metrics, step=step)
            
            duration = time.time() - start_time
            
            test_results.add_test(
                "å¤§é‡æŒ‡æ ‡è®°å½•",
                True,
                f"æˆåŠŸè®°å½• {num_steps} x {num_metrics_per_step} = {num_steps * num_metrics_per_step} ä¸ªæŒ‡æ ‡"
            )
            
            test_results.add_test(
                "æ€§èƒ½æµ‹è¯•",
                True,
                f"è€—æ—¶ {duration:.2f}s, å¹³å‡ {num_steps/duration:.1f} steps/s"
            )
        
        except Exception as e:
            test_results.add_test("å¤§é‡æŒ‡æ ‡è®°å½•", False, f"å¤±è´¥: {e}")
        
        wandb.finish()
        
        # ç­‰å¾…å¼‚æ­¥ä¸ŠæŠ¥
        time.sleep(5.0)
        
        # éªŒè¯æ–‡ä»¶ï¼ˆä½¿ç”¨ rank_-1ï¼Œå› ä¸ºæœªè®¾ç½® RANK ç¯å¢ƒå˜é‡ï¼‰
        success, message = verify_metrics_file(tmpdir, node_rank=0, local_rank=-1)
        test_results.add_test("å‹åŠ›æµ‹è¯•æ–‡ä»¶å®Œæ•´æ€§", success, message)
        
        # æ£€æŸ¥ä¸ŠæŠ¥ç»Ÿè®¡
        try:
            from primus_lens_wandb_exporter.api_reporter import get_global_reporter
            reporter = get_global_reporter()
            stats = reporter.stats
            
            test_results.add_test(
                "å‹åŠ›æµ‹è¯•ä¸ŠæŠ¥",
                stats['errors'] == 0,
                f"æŒ‡æ ‡æ‰¹æ¬¡: {stats['metrics_sent']}, é”™è¯¯: {stats['errors']}"
            )
        except:
            pass
    
    finally:
        test_results.end_scenario()
        if tmpdir:
            cleanup_environment(tmpdir)


def test_scenario_edge_cases():
    """åœºæ™¯5: è¾¹ç¼˜æƒ…å†µæµ‹è¯•"""
    test_results.start_scenario(
        "è¾¹ç¼˜æƒ…å†µ",
        "æµ‹è¯•å¼‚å¸¸è¾“å…¥ã€é”™è¯¯å¤„ç†ç­‰è¾¹ç¼˜æƒ…å†µ"
    )
    
    tmpdir = None
    try:
        tmpdir = setup_environment(enable_api=False, force_hook=True)
        
        # å¯¼å…¥ wandbï¼ˆä¸è¦åˆ é™¤æ¨¡å—ï¼‰
        import wandb
        
        # æµ‹è¯•1: ç©ºæŒ‡æ ‡
        run = wandb.init(project="edge-test", name="empty-metrics", reinit=True)
        try:
            wandb.log({}, step=0)
            test_results.add_test("ç©ºæŒ‡æ ‡è®°å½•", True, "ç©ºæŒ‡æ ‡ä¸ä¼šå¯¼è‡´å´©æºƒ")
        except Exception as e:
            test_results.add_test("ç©ºæŒ‡æ ‡è®°å½•", False, f"å¤±è´¥: {e}")
        wandb.finish()
        
        # æµ‹è¯•2: åŒ…å«éæ•°å€¼ç±»å‹çš„æŒ‡æ ‡
        run = wandb.init(project="edge-test", name="mixed-types", reinit=True)
        try:
            wandb.log({
                "loss": 0.5,
                "name": "test",  # å­—ç¬¦ä¸²
                "config": {"lr": 0.001},  # å­—å…¸
                "data": [1, 2, 3],  # åˆ—è¡¨
            }, step=0)
            test_results.add_test("æ··åˆç±»å‹æŒ‡æ ‡", True, "æ··åˆç±»å‹ä¸ä¼šå¯¼è‡´å´©æºƒ")
        except Exception as e:
            test_results.add_test("æ··åˆç±»å‹æŒ‡æ ‡", False, f"å¤±è´¥: {e}")
        wandb.finish()
        
        # æµ‹è¯•3: æ— è¾“å‡ºè·¯å¾„
        old_path = os.environ.pop("PRIMUS_LENS_WANDB_OUTPUT_PATH", None)
        run = wandb.init(project="edge-test", name="no-output-path", reinit=True)
        try:
            wandb.log({"loss": 0.5}, step=0)
            test_results.add_test("æ— è¾“å‡ºè·¯å¾„", True, "ç¼ºå°‘è¾“å‡ºè·¯å¾„ä¸ä¼šå¯¼è‡´å´©æºƒ")
        except Exception as e:
            test_results.add_test("æ— è¾“å‡ºè·¯å¾„", False, f"å¤±è´¥: {e}")
        finally:
            if old_path:
                os.environ["PRIMUS_LENS_WANDB_OUTPUT_PATH"] = old_path
        wandb.finish()
        
        # æµ‹è¯•4: ç¦ç”¨åŠŸèƒ½åçš„è¡Œä¸º
        # æ³¨æ„ï¼šéœ€è¦åˆ é™¤å¹¶é‡æ–°å¯¼å…¥æ¥æµ‹è¯•ç¦ç”¨åŠŸèƒ½
        os.environ["PRIMUS_LENS_WANDB_HOOK"] = "false"
        if 'wandb' in sys.modules:
            # åˆ é™¤æ‰€æœ‰ç›¸å…³æ¨¡å—
            wandb_modules = [m for m in sys.modules.keys() if m.startswith('wandb') or m.startswith('primus_lens_wandb')]
            for mod in wandb_modules:
                del sys.modules[mod]
        
        import wandb
        
        is_patched = hasattr(wandb, '_primus_lens_patched')
        test_results.add_test(
            "ç¦ç”¨åŠ«æŒ",
            not is_patched,
            "è®¾ç½® HOOK=false ååŠ«æŒè¢«æ­£ç¡®ç¦ç”¨"
        )
        
        # æ¢å¤è®¾ç½®
        os.environ["PRIMUS_LENS_WANDB_HOOK"] = "true"
    
    finally:
        test_results.end_scenario()
        if tmpdir:
            cleanup_environment(tmpdir)


# ========== ä¸»ç¨‹åº ==========

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="WandB Exporter çœŸå®åœºæ™¯æµ‹è¯•ç¨‹åº",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
åœºæ™¯è¯´æ˜:
  basic        - åŸºç¡€å•æœºè®­ç»ƒåœºæ™¯
  distributed  - åˆ†å¸ƒå¼è®­ç»ƒåœºæ™¯ï¼ˆå¤šèŠ‚ç‚¹ã€å¤šGPUï¼‰
  api          - API å¼‚æ­¥ä¸ŠæŠ¥åœºæ™¯
  stress       - å‹åŠ›æµ‹è¯•åœºæ™¯ï¼ˆå¤§é‡æŒ‡æ ‡ï¼‰
  edge         - è¾¹ç¼˜æƒ…å†µæµ‹è¯•
  all          - è¿è¡Œæ‰€æœ‰åœºæ™¯ï¼ˆé»˜è®¤ï¼‰
        """
    )
    parser.add_argument(
        '--scenario',
        choices=['basic', 'distributed', 'api', 'stress', 'edge', 'all'],
        default='all',
        help='è¦è¿è¡Œçš„æµ‹è¯•åœºæ™¯'
    )
    
    args = parser.parse_args()
    
    print("\n" + "="*70)
    print("WandB Exporter çœŸå®åœºæ™¯æµ‹è¯•")
    print("="*70)
    print(f"\nPython ç‰ˆæœ¬: {sys.version}")
    print(f"å·¥ä½œç›®å½•: {os.getcwd()}\n")
    
    # åœ¨å¯¼å…¥ wandb ä¹‹å‰ï¼Œå…ˆå¯¼å…¥åŠ«æŒæ¨¡å—
    print("é¢„åŠ è½½åŠ«æŒæ¨¡å—...")
    try:
        src_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'src')
        if src_path not in sys.path:
            sys.path.insert(0, src_path)
        import primus_lens_wandb_exporter.wandb_hook
        print("âœ“ åŠ«æŒæ¨¡å—å·²åŠ è½½\n")
    except Exception as e:
        print(f"âš  åŠ«æŒæ¨¡å—åŠ è½½å¤±è´¥: {e}\n")
    
    # æ£€æŸ¥ä¾èµ–
    try:
        import wandb
        print(f"âœ“ WandB å·²å®‰è£…: {wandb.__version__}")
    except ImportError:
        print("âœ— WandB æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install wandb")
        return 1
    
    try:
        import psutil
        print(f"âœ“ psutil å·²å®‰è£… (å¯ä»¥æ”¶é›†ç³»ç»ŸæŒ‡æ ‡)")
    except ImportError:
        print("âš  psutil æœªå®‰è£… (å°†è·³è¿‡ç³»ç»ŸæŒ‡æ ‡æ”¶é›†)")
    
    print()
    
    # è¿è¡Œæµ‹è¯•åœºæ™¯
    scenarios = {
        'basic': test_scenario_basic,
        'distributed': test_scenario_distributed,
        'api': test_scenario_api_reporting,
        'stress': test_scenario_stress,
        'edge': test_scenario_edge_cases,
    }
    
    if args.scenario == 'all':
        for scenario_func in scenarios.values():
            try:
                scenario_func()
            except Exception as e:
                print(f"\nâœ— åœºæ™¯æ‰§è¡Œå¼‚å¸¸: {e}")
                import traceback
                traceback.print_exc()
    else:
        scenarios[args.scenario]()
    
    # æ‰“å°æ€»ç»“
    return test_results.print_summary()


if __name__ == "__main__":
    try:
        exit_code = main()
        sys.exit(exit_code)
    except KeyboardInterrupt:
        print("\n\næµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"\n\nâœ— æµ‹è¯•ç¨‹åºå¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

