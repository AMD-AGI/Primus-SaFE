/*
 * Copyright (C) 2025-2026, Advanced Micro Devices, Inc. All rights reserved.
 * See LICENSE for license information.
 */
// Code generated by informer-gen. DO NOT EDIT.

package v1

import (
	context "context"
	time "time"

	apisamdv1 "github.com/AMD-AIG-AIMA/SAFE/apis/pkg/apis/amd/v1"
	versioned "github.com/AMD-AIG-AIMA/SAFE/apis/pkg/client/clientset/versioned"
	internalinterfaces "github.com/AMD-AIG-AIMA/SAFE/apis/pkg/client/informers/externalversions/internalinterfaces"
	amdv1 "github.com/AMD-AIG-AIMA/SAFE/apis/pkg/client/listers/amd/v1"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	runtime "k8s.io/apimachinery/pkg/runtime"
	watch "k8s.io/apimachinery/pkg/watch"
	cache "k8s.io/client-go/tools/cache"
)

// InferenceInformer provides access to a shared informer and lister for
// Inferences.
type InferenceInformer interface {
	Informer() cache.SharedIndexInformer
	Lister() amdv1.InferenceLister
}

type inferenceInformer struct {
	factory          internalinterfaces.SharedInformerFactory
	tweakListOptions internalinterfaces.TweakListOptionsFunc
	namespace        string
}

// NewInferenceInformer constructs a new informer for Inference type.
// Always prefer using an informer factory to get a shared informer instead of getting an independent
// one. This reduces memory footprint and number of connections to the server.
func NewInferenceInformer(client versioned.Interface, namespace string, resyncPeriod time.Duration, indexers cache.Indexers) cache.SharedIndexInformer {
	return NewFilteredInferenceInformer(client, namespace, resyncPeriod, indexers, nil)
}

// NewFilteredInferenceInformer constructs a new informer for Inference type.
// Always prefer using an informer factory to get a shared informer instead of getting an independent
// one. This reduces memory footprint and number of connections to the server.
func NewFilteredInferenceInformer(client versioned.Interface, namespace string, resyncPeriod time.Duration, indexers cache.Indexers, tweakListOptions internalinterfaces.TweakListOptionsFunc) cache.SharedIndexInformer {
	return cache.NewSharedIndexInformer(
		&cache.ListWatch{
			ListFunc: func(options metav1.ListOptions) (runtime.Object, error) {
				if tweakListOptions != nil {
					tweakListOptions(&options)
				}
				return client.AmdV1().Inferences(namespace).List(context.Background(), options)
			},
			WatchFunc: func(options metav1.ListOptions) (watch.Interface, error) {
				if tweakListOptions != nil {
					tweakListOptions(&options)
				}
				return client.AmdV1().Inferences(namespace).Watch(context.Background(), options)
			},
			ListWithContextFunc: func(ctx context.Context, options metav1.ListOptions) (runtime.Object, error) {
				if tweakListOptions != nil {
					tweakListOptions(&options)
				}
				return client.AmdV1().Inferences(namespace).List(ctx, options)
			},
			WatchFuncWithContext: func(ctx context.Context, options metav1.ListOptions) (watch.Interface, error) {
				if tweakListOptions != nil {
					tweakListOptions(&options)
				}
				return client.AmdV1().Inferences(namespace).Watch(ctx, options)
			},
		},
		&apisamdv1.Inference{},
		resyncPeriod,
		indexers,
	)
}

func (f *inferenceInformer) defaultInformer(client versioned.Interface, resyncPeriod time.Duration) cache.SharedIndexInformer {
	return NewFilteredInferenceInformer(client, f.namespace, resyncPeriod, cache.Indexers{cache.NamespaceIndex: cache.MetaNamespaceIndexFunc}, f.tweakListOptions)
}

func (f *inferenceInformer) Informer() cache.SharedIndexInformer {
	return f.factory.InformerFor(&apisamdv1.Inference{}, f.defaultInformer)
}

func (f *inferenceInformer) Lister() amdv1.InferenceLister {
	return amdv1.NewInferenceLister(f.Informer().GetIndexer())
}
